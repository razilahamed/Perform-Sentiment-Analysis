{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e50183c",
      "metadata": {
        "id": "4e50183c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f3d9a22a",
      "metadata": {
        "id": "f3d9a22a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"IMDB Dataset.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6b3669a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b3669a9",
        "outputId": "a20d5236-e53a-4fb7-b770-605eda4f68e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7397f737",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7397f737",
        "outputId": "3d04eb31-0baf-450a-e093-6d1131492d39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sentiment\n",
              "positive    25000\n",
              "negative    25000\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "caad96eb",
      "metadata": {
        "id": "caad96eb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# positive -> 1\n",
        "# negative -> 0\n",
        "data.replace({\"sentiment\": {\"positive\": 1, \"negative\": 0}}, inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "beb564c1",
      "metadata": {
        "id": "beb564c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12500, 2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size = 0.25, random_state=42)\n",
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5940cc46",
      "metadata": {
        "id": "5940cc46"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_data[\"review\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e98b4624",
      "metadata": {
        "id": "e98b4624"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"review\"]), maxlen=200)\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"review\"]), maxlen=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "64d8caac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64d8caac",
        "outputId": "0d40ca76-e404-4e44-bc0a-198c0c75a0fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    1,   13,  190],\n",
              "       [ 148,   48,    1, ...,  103,    3,  577],\n",
              "       [   0,    0,    0, ...,  292,   29, 2104],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 1614,    2,  593],\n",
              "       [   0,    0,    0, ...,  246,  103,  125],\n",
              "       [   0,    0,    0, ...,   70,   72, 2069]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b71824f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71824f5",
        "outputId": "b08b35a6-ed57-4b52-c1f6-0979c57b65d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(12500, 200)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "153a60a4",
      "metadata": {
        "id": "153a60a4"
      },
      "outputs": [],
      "source": [
        "Y_train = train_data[\"sentiment\"]\n",
        "Y_test = test_data[\"sentiment\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "67680bfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67680bfe",
        "outputId": "b42e160e-30aa-4ec9-a2ef-626e2b04db7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27434    0\n",
              "13400    0\n",
              "883      0\n",
              "7303     0\n",
              "45124    1\n",
              "        ..\n",
              "11284    1\n",
              "44732    1\n",
              "38158    0\n",
              "860      1\n",
              "15795    1\n",
              "Name: sentiment, Length: 37500, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "85db55b4",
      "metadata": {
        "id": "85db55b4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m640,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771,713</span> (2.94 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771,713\u001b[0m (2.94 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# LSTM MODEL BUILDING\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_shape=(200,)))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d1313669",
      "metadata": {
        "id": "d1313669"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = \"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9c8d3e3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c8d3e3d",
        "outputId": "c497b5ff-33cb-48d0-fc58-3fa631a1523c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 361ms/step - accuracy: 0.7234 - loss: 0.5400 - val_accuracy: 0.7861 - val_loss: 0.4510\n",
            "Epoch 2/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 358ms/step - accuracy: 0.8382 - loss: 0.3802 - val_accuracy: 0.8171 - val_loss: 0.3996\n",
            "Epoch 3/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 339ms/step - accuracy: 0.8747 - loss: 0.3154 - val_accuracy: 0.8453 - val_loss: 0.3573\n",
            "Epoch 4/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 337ms/step - accuracy: 0.8812 - loss: 0.2940 - val_accuracy: 0.8541 - val_loss: 0.3596\n",
            "Epoch 5/5\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 365ms/step - accuracy: 0.8739 - loss: 0.3041 - val_accuracy: 0.8693 - val_loss: 0.3334\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1ba35db82f0>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs = 5, batch_size = 64, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ca098a76",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 62ms/step - accuracy: 0.8776 - loss: 0.3231\n",
            "Model Accuracy: 87.49%\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print(\"Model Accuracy: {:.2f}%\".format(accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "02f781f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Building Predictive System\n",
        "\n",
        "def predictive_system(review):\n",
        "  sequences = tokenizer.texts_to_sequences([review])\n",
        "  padded_sequence = pad_sequences(sequences, maxlen=200)\n",
        "  prediction = model.predict(padded_sequence)\n",
        "  sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
        "  return sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "45d08c1d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictive_system(\"This movie was fantastic and amazing\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e58aa69d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'negative'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictive_system(\"Overall long and slow, boring\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bbfa9987",
      "metadata": {
        "id": "bbfa9987"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "Z5NnN-0hFBGI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5NnN-0hFBGI",
        "outputId": "4f709c84-24d6-48fc-aa47-8dd51684aa32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['tokenizer.pkl']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(tokenizer, \"tokenizer.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "STCsgeezE3pq",
      "metadata": {
        "id": "STCsgeezE3pq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "import joblib\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "model = load_model(\"model.h5\")\n",
        "tokenizer = joblib.load(\"tokenizer.pkl\")\n",
        "\n",
        "def predictive_system(review):\n",
        "  sequences = tokenizer.texts_to_sequences([review])\n",
        "  padded_sequence = pad_sequences(sequences, maxlen=200)\n",
        "  prediction = model.predict(padded_sequence)\n",
        "  sentiment = \"positive\" if prediction[0][0] > 0.5 else \"negative\"\n",
        "  return sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "-2D2nGg5F3JZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-2D2nGg5F3JZ",
        "outputId": "39f0ecfc-d399-4550-b9fe-5156d068e695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'positive'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "review_sentiment = predictive_system(\"Beautiful cinematorgraphy\")\n",
        "review_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "47b00d17",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Using cached gradio-4.38.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Using cached aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting altair<6.0,>=5.0 (from gradio)\n",
            "  Using cached altair-5.3.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Using cached ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting gradio-client==1.1.0 (from gradio)\n",
            "  Using cached gradio_client-1.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (0.27.0)\n",
            "Collecting huggingface-hub>=0.19.3 (from gradio)\n",
            "  Downloading huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (3.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp312-none-win_amd64.whl.metadata (51 kB)\n",
            "     ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
            "     ------- -------------------------------- 10.2/51.6 kB ? eta -:--:--\n",
            "     ------------------------------ ------- 41.0/51.6 kB 393.8 kB/s eta 0:00:01\n",
            "     -------------------------------------- 51.6/51.6 kB 530.9 kB/s eta 0:00:00\n",
            "Requirement already satisfied: packaging in c:\\users\\razil\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (10.3.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "Collecting pydub (from gradio)\n",
            "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Using cached python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.3-py3-none-win_amd64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Using cached tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from gradio) (2.2.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting fsspec (from gradio-client==1.1.0->gradio)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.0->gradio)\n",
            "  Downloading websockets-11.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from altair<6.0,>=5.0->gradio) (4.22.0)\n",
            "Collecting toolz (from altair<6.0,>=5.0->gradio)\n",
            "  Using cached toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: anyio in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpx>=0.24.1->gradio) (4.4.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Collecting filelock (from huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: requests in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Collecting tqdm>=4.42.1 (from huggingface-hub>=0.19.3->gradio)\n",
            "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\razil\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic>=2.0->gradio)\n",
            "  Downloading pydantic_core-2.20.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Using cached fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\razil\\appdata\\roaming\\python\\python312\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\razil\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\razil\\appdata\\roaming\\python\\python312\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0->fastapi->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\razil\\.conda\\envs\\ser-env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Using cached gradio-4.38.1-py3-none-any.whl (12.4 MB)\n",
            "Using cached gradio_client-1.1.0-py3-none-any.whl (318 kB)\n",
            "Using cached tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Using cached aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Using cached altair-5.3.0-py3-none-any.whl (857 kB)\n",
            "Downloading huggingface_hub-0.24.0-py3-none-any.whl (419 kB)\n",
            "   ---------------------------------------- 0.0/419.0 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 92.2/419.0 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 92.2/419.0 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 92.2/419.0 kB ? eta -:--:--\n",
            "   -------- ------------------------------- 92.2/419.0 kB ? eta -:--:--\n",
            "   --------------------- ------------------ 225.3/419.0 kB 1.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 225.3/419.0 kB 1.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 225.3/419.0 kB 1.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 225.3/419.0 kB 1.1 MB/s eta 0:00:01\n",
            "   -------------------------------------  409.6/419.0 kB 981.2 kB/s eta 0:00:01\n",
            "   -------------------------------------- 419.0/419.0 kB 968.7 kB/s eta 0:00:00\n",
            "Downloading orjson-3.10.6-cp312-none-win_amd64.whl (136 kB)\n",
            "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 136.4/136.4 kB 8.4 MB/s eta 0:00:00\n",
            "Using cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "Downloading pydantic_core-2.20.1-cp312-none-win_amd64.whl (1.9 MB)\n",
            "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
            "   ------- -------------------------------- 0.4/1.9 MB 11.2 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 0.4/1.9 MB 11.2 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 0.8/1.9 MB 5.4 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 1.1/1.9 MB 7.1 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.4/1.9 MB 5.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  1.9/1.9 MB 7.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.9/1.9 MB 6.4 MB/s eta 0:00:00\n",
            "Using cached python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.3-py3-none-win_amd64.whl (8.6 MB)\n",
            "   ---------------------------------------- 0.0/8.6 MB ? eta -:--:--\n",
            "   ----- ---------------------------------- 1.2/8.6 MB 36.2 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 1.7/8.6 MB 21.8 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.3/8.6 MB 16.1 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 2.8/8.6 MB 16.4 MB/s eta 0:00:01\n",
            "   --------------- ------------------------ 3.4/8.6 MB 15.4 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 3.9/8.6 MB 14.7 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 4.5/8.6 MB 14.3 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 5.0/8.6 MB 14.0 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 5.6/8.6 MB 13.8 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 6.2/8.6 MB 13.5 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 6.7/8.6 MB 13.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 7.2/8.6 MB 13.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 7.8/8.6 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  8.4/8.6 MB 12.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  8.6/8.6 MB 12.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.6/8.6 MB 12.2 MB/s eta 0:00:00\n",
            "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 62.4/62.4 kB ? eta 0:00:00\n",
            "Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "   ---------------------------------------- 0.0/92.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 92.2/92.2 kB ? eta 0:00:00\n",
            "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Using cached fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "   ---------------------------------------- 0.0/177.6 kB ? eta -:--:--\n",
            "   --------------------------------------- 177.6/177.6 kB 10.5 MB/s eta 0:00:00\n",
            "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
            "Downloading websockets-11.0.3-py3-none-any.whl (118 kB)\n",
            "   ---------------------------------------- 0.0/118.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 118.1/118.1 kB ? eta 0:00:00\n",
            "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Using cached toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "Downloading httptools-0.6.1-cp312-cp312-win_amd64.whl (55 kB)\n",
            "   ---------------------------------------- 0.0/55.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 55.7/55.7 kB ? eta 0:00:00\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading watchfiles-0.22.0-cp312-none-win_amd64.whl (280 kB)\n",
            "   ---------------------------------------- 0.0/281.0 kB ? eta -:--:--\n",
            "   ---------------------------------------- 281.0/281.0 kB ? eta 0:00:00\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py): started\n",
            "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5605 sha256=35e527edd5f0bc1e4d80388fd0d94fa3aefc6a0e1db7f0d3628a7cf93c011c1a\n",
            "  Stored in directory: c:\\users\\razil\\appdata\\local\\pip\\cache\\wheels\\8a\\63\\a8\\fad16a1c5c990569a478f40782ce543788ddac224288008635\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tqdm, toolz, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, pydantic-core, orjson, httptools, fsspec, filelock, dnspython, annotated-types, aiofiles, watchfiles, uvicorn, starlette, pydantic, huggingface-hub, email_validator, typer, gradio-client, fastapi-cli, altair, fastapi, gradio\n",
            "Successfully installed aiofiles-23.2.1 altair-5.3.0 annotated-types-0.7.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 filelock-3.15.4 fsspec-2024.6.1 gradio-4.38.1 gradio-client-1.1.0 httptools-0.6.1 huggingface-hub-0.24.0 orjson-3.10.6 pydantic-2.8.2 pydantic-core-2.20.1 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 toolz-0.12.1 tqdm-4.66.4 typer-0.12.3 uvicorn-0.30.1 watchfiles-0.22.0 websockets-11.0.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "59qOFXkHHGtR",
      "metadata": {
        "id": "59qOFXkHHGtR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "title = \"MOVIE SENTIMENT ANALYSIS APPLICATION\"\n",
        "\n",
        "app = gr.Interface(fn = predictive_system, inputs=\"textbox\", outputs=\"textbox\", title=title)\n",
        "\n",
        "app.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
